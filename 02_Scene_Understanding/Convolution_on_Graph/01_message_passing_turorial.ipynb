{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sample node feature\n",
    "X = torch.Tensor(torch.randn(6,3)) # torch.randn(#_of_node_feature, feature_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sample adjacency matrix\n",
    "adj = torch.Tensor([[0,1,0,0,1,0],\n",
    "                    [1,0,1,0,1,0],\n",
    "                    [0,1,0,1,0,0],\n",
    "                    [0,0,1,0,1,1],\n",
    "                    [1,1,0,1,0,0],\n",
    "                    [0,0,0,1,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 0., 0., 1., 0.],\n",
      "        [1., 0., 1., 0., 1., 0.],\n",
      "        [0., 1., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 1., 1.],\n",
      "        [1., 1., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.]])\n",
      "torch.Size([6, 6])\n"
     ]
    }
   ],
   "source": [
    "print(adj)\n",
    "print(adj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 0., 0., 1., 0.],\n",
      "        [1., 1., 1., 0., 1., 0.],\n",
      "        [0., 1., 1., 1., 0., 0.],\n",
      "        [0., 0., 1., 1., 1., 1.],\n",
      "        [1., 1., 0., 1., 1., 0.],\n",
      "        [0., 0., 0., 1., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# need self loops to use self informations\n",
    "tilde = adj + torch.eye(adj.shape[0])\n",
    "print(tilde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5],\n",
      "        [0, 1, 4, 0, 1, 2, 4, 1, 2, 3, 2, 3, 4, 5, 0, 1, 3, 4, 3, 5]])\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "torch.Size([6, 6])\n"
     ]
    }
   ],
   "source": [
    "# to sparse matrix\n",
    "sps = tilde.to_sparse()\n",
    "print(sps.indices())\n",
    "print(sps.values())\n",
    "print(sps.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Z = \\tilde{D}^{-{1\\over2}} \\tilde{A} \\tilde{D}^{-{1\\over2}} X\\theta$\n",
    "\n",
    "위 식에서 normalize 부분($\\tilde{D}^{-{1\\over2}}$)은 잠시 제외하고 계산을 해보자. ($X\\theta$도 여기서는 초기화된 행렬 X로 가정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4045, -0.7183,  0.4900],\n",
      "        [-0.7149, -3.0254, -0.7417],\n",
      "        [-0.9960, -1.0151, -1.3487],\n",
      "        [-1.2980,  3.3590, -0.8335],\n",
      "        [ 0.3266,  1.1231,  0.9904],\n",
      "        [-1.6103,  0.4507, -0.0049]])\n",
      "tensor([[1., 1., 0., 0., 1., 0.],\n",
      "        [1., 1., 1., 0., 1., 0.],\n",
      "        [0., 1., 1., 1., 0., 0.],\n",
      "        [0., 0., 1., 1., 1., 1.],\n",
      "        [1., 1., 0., 1., 1., 0.],\n",
      "        [0., 0., 0., 1., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(tilde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.7927, -2.6206,  0.7387],\n",
      "        [-2.7887, -3.6357, -0.6101],\n",
      "        [-3.0089, -0.6816, -2.9239],\n",
      "        [-3.5776,  3.9176, -1.1968],\n",
      "        [-3.0908,  0.7384, -0.0948],\n",
      "        [-2.9083,  3.8096, -0.8384]])\n"
     ]
    }
   ],
   "source": [
    "Z = torch.matmul(tilde, X)\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 4., 3., 4., 4., 2.])\n",
      "tensor([3., 4., 3., 4., 4., 2.])\n"
     ]
    }
   ],
   "source": [
    "# Normalize term D\n",
    "D1 = tilde.sum(dim=0)\n",
    "D2 = tilde.sum(dim=1)\n",
    "print(D1)\n",
    "print(D2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Degree의 개수로 normalize를 시켜주는 작업으로, directed graph에서 indegree와 outdegree가 다를 때도 normalize가 가능하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Z = \\tilde{D1}^{-{1\\over2}} \\tilde{A} \\tilde{D2}^{-{1\\over2}} X\\theta$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -5.7665,  -9.7640,   2.4646],\n",
      "        [ -8.7544, -12.8094,  -1.5816],\n",
      "        [-11.0398,  -1.7112, -10.3470],\n",
      "        [-10.0940,  15.7843,  -3.4286],\n",
      "        [-10.9587,   3.6719,  -0.8693],\n",
      "        [ -8.4127,  14.3372,  -3.3438]])\n"
     ]
    }
   ],
   "source": [
    "normalized_tilde = ((D1**(0.5)*tilde)*(D2**(0.5)))\n",
    "normalized_Z = torch.matmul(normalized_tilde, X)\n",
    "print(normalized_Z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('pytorch_vision')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "616154aabd2dc14828d91158a7112b56c3a867c588e59d80a617e79dec008fb9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
